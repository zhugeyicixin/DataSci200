# This file contains the lectures and their associated information in
# chronological order. Note that the week and lecture numbers are automatically
# generated by the code in syllabus_entries.html.
#
# The schema for a lecture entry is:
#
#
# - date: Date of the lecture
#   topic: Title of the lecture
#   description: Longer description of lecture content
#   slides: url to the lecture slide
#   readings: markdown text for resources
#   lab
#   discussion
#   homework
#   project
#
# Python script to generate the dates:
#
# import datetime
# import pandas as pd
#
# d1 = datetime.date(2017,8,24)
# d2 = datetime.date(2017,12,14)
# days = pd.date_range(d1,d2)
#
# for d in days[(days.dayofweek == 1) | (days.dayofweek == 3)]:
#     print(str(d.month) + "/" + str(d.day) + "/" + str(d.year))


# - date: 8/23/18
#   topic: Course Overview, Data Design and Sources of Bias
#   description: In this lecture we provide an overview of what data science is at its
#     root and the components that make data science a large field with endless possibilities.
#     Fundamentally, (data) science is the study of using data to learn about the world
#     and solve problems. However, how and what data is collected can have a profound
#     impact on what we can learn and the problems we can solve. Along the way, we will
#     also touch on what it means to be a data scientist by examining recent surveys
#     of data scientists. We will begin to explore various mechanisms for data collection
#     and their implications on our ability to generalize. In particular, we will discuss
#     differences between censuses, surveys, controlled experiments, and observational
#     studies and will also highlight the power of simple randomization and the fallacies
#     of data at scale. Welcome to Data 100!
#   slides: https://docs.google.com/presentation/d/1Y7sdF-q27CjbGO58gpYcYS9Fgz3PSkZJcXDyOuJqiTQ/edit?usp=sharing
#   resources: |
#     - [Demo Notebook](assets/lectures/lec1.zip) (also on Datahub)
#     - [Textbook: Data Science Life Cycle](https://www.textbook.ds100.org/ch/01/lifecycle_intro.html)
#     - [Textbook: Data Design](https://www.textbook.ds100.org/ch/02/design_intro.html)
#     - [Screencast](https://www.youtube.com/watch?v=NplaZECopOs)
#   discussion: |
#     - Disc0
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc00/disc00.ipynb)
#   homework: |
#     - HW0 Released
#     - [HW0 Solutions](https://nbviewer.jupyter.org/github/DS-100/fa18/blob/master/hw/hw0/hw0.ipynb)

# - date: 8/28/18
#   topic: Data Manipulation with Pandas I
#   description: While data comes in many forms, most data analyses are performed on
#     tabular data. Mastering the skills of constructing, cleaning, joining, aggregating,
#     and manipulating tabular data is essential to data science. In this lecture we
#     will introduce Pandas, the open-source Python data manipulation and analysis library
#     widely used by data scientists. Through introducing useful Pandas operations and
#     paradigms, we will also bring to light new concepts including indices, column
#     operations (and their effect on system performance), grouping operations, and
#     basic data visualization tools built to accompany Pandas.
#   lab: |
#     - Lab1
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab01/lab01_solution.ipynb)
#   discussion: |
#     - [Disc1](assets/discussions/disc01.pdf)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc01/disc01_solution.pdf)
#   slides: https://docs.google.com/presentation/d/1qMRtloXaccvJLfyZckn-UpuG0Prb1XtJHLPWQX2OMSo/edit?usp=sharing
#   resources: |
#     - [Textbook: Tabular Data](https://www.textbook.ds100.org/ch/03/pandas_intro.html)
#     - [Demo Notebook](assets/lectures/lec02.zip) (also on Datahub)
#       1. [Pandas Basics (HTML)](assets/lectures/lec02/02-pandas-basics.nbconvert.html)
#       2. [Case Study (HTML)](assets/lectures/lec02/02-case-study.nbconvert.html)
#     - [Screencast](https://www.youtube.com/watch?v=mYEP5QmEHYY)

# - date: 8/30/18
#   topic: Data Manipulation with Pandas II
#   description: Continued discussion of material in the previous lecture.
#   slides: https://docs.google.com/presentation/d/1FrYg6yd6B-CIgfWLWm4W8vBhfmJ6Qt9dKkN-mlN5AKU/edit?usp=sharing
#   resources: |
#     - [Demo Notebook on Datahub](https://data100.datahub.berkeley.edu/hub/home)
#       1. [Case Study (HTML)](assets/lectures/lec03/03-case-study.html)
#       2. [Enrollment Exercise (HTML)](assets/lectures/lec03/03-enrollment-exercise.html)
#       3. [Groupby & Pivot (HTML)](assets/lectures/lec03/03-groupby-and-pivot-basics.html)
#     - [Screencast](https://www.youtube.com/watch?v=SonWCfrY_ek)

# - date: 9/4/18
#   topic: Data Cleaning & EDA
#   description: Whether collected by you or obtained from someone else, raw data is
#     seldom ready for immediate analysis. Data cleaning is an important skill every
#     data scientist should master and it starts with understanding key aspects of the
#     data. Through exploratory data analysis we can often discover important anomalies,
#     identify limitations in the collection process, and better inform subsequent goal-oriented
#     analysis. In this lecture we will discuss how to identify and correct common data
#     anomalies and analyze their implications on future analysis. We will also discuss
#     key properties of data including structure, granularity, faithfulness, temporality,
#     and scope; these properties can inform how we prepare, analyze, and visualize
#     data.
#   slides: assets/lectures/lec04/04-EDA-and-Cleaning.pdf
#   lab: |
#     - Lab2
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab02/lab02_solution.ipynb)
#   discussion: Lab2
#   homework: |
#     - HW0 Due, HW1 Released
#     - [HW1 Solutions](https://nbviewer.jupyter.org/github/DS-100/fa18/blob/master/hw/hw1/hw1.ipynb)
#   resources: |
#     - [Textbook: Data Cleaning](https://www.textbook.ds100.org/ch/04/cleaning_intro.html)
#     - [Demo Notebook (ZIP)](assets/lectures/lec04/lec04.zip)
#       1. [Groupby Pivot and Merge (HTML)](assets/lectures/lec04/groupby_pivot_and_merge.html)
#     - [Screencast](https://www.youtube.com/watch?v=aOZogO1rBak)

# - date: 9/6/18
#   topic: EDA and Visualization
#   description: In this lecture we will continue our discussion of EDA and important
#     features we should be identifying when given a dataset. Along the way, we will
#     start to work through a real-world exercise in EDA using public crime data for
#     the city of Berkeley. Through this, we will also introduce tools for data visualization
#     using Pandas, Seaborn, and Matplotlib.
#   slides: assets/lectures/lec05/05-EDA-Continued.pptx
#   resources: |
#     - [Textbook: EDA](https://www.textbook.ds100.org/ch/05/eda_intro.html)
#     - [EDA_and_Cleaning notebook (HTML)](assets/lectures/lec05/EDA_and_Cleaning.html)
#     - [code and data (includes notebooks and scripts as needed)](assets/lectures/lec05/code.zip)
#     - [Screencast](https://www.youtube.com/watch?v=cSkfvBKi-rw)

# - date: 9/11/18
#   topic: Visualization and Data Transformations
#   description: A large fraction of the human brain is devoted to visual perception.
#     As a consequence, visualization is a critical tool in both exploratory data analysis
#     and the communication of complex relationships in data. However, making informative
#     and clear visualizations of complex concepts can be challenging. In this lecture
#     we explore good and bad visualizations and describe how to choose visualizations
#     for various kinds of data and goals. We will also go into detail on how to identify
#     issues with certain visualizations and ways to fix these issues to properly convey
#     the message you are trying to show. However, in some cases, directly visualizing
#     data can be uninformative. Some examples of these cases include plots with curvilinear
#     relationships, large numbers of similar observations hiding core trends in the
#     data, and visualizing data with a large number of variables. In this lecture we
#     discuss data transformations, smoothing, and dimensionality reduction to address
#     the challenges in creating informative visualizations. The Tukey-Mosteller Bulge
#     Diagram will come in handy when talking about transformations and is a great tool
#     for identifying when data needs to be transformed. With these additional analytics
#     we can often reveal important and informative patterns in data.
#   slides: assets/lectures/lec06/06-visualization.pptx
#   lab: |
#     - Lab3
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab03/lab03_solution.ipynb)
#   discussion: |
#     - [Disc3](https://github.com/DS-100/fa18/blob/master/disc/disc03/disc03.pdf)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc03/dis03_solution.pdf)
#     - [TA Slides](https://docs.google.com/presentation/d/1PzQG3YtC8FLp_aK9KMTpdRiPOldRTKGBTJTMuHMRlL0/edit?usp=sharing)
#   resources: |
#     - [Textbook: Data Visualization](https://www.textbook.ds100.org/ch/06/viz_intro.html)
#     - [Screencast](https://www.youtube.com/watch?v=AwFsWvNVts8)

# - date: 9/13/18
#   topic: Working with Text
#   description: Whether in documents, tweets, or records in a table, text data is
#     ubiquitous and presents a unique set of challenges for data scientists. How
#     do you extract key phrases from text? What are meaningful aggregate summaries
#     of text? How do you visualize textual data? In this lecture we will introduce
#     a set of techniques (e.g. bag-of-words) to transform text into numerical data
#     for subsequent tabular analysis. We will also introduce regular expressions
#     as a mechanism for cleaning and transforming text data.
#   slides: https://docs.google.com/presentation/d/1ECr_XrDJXaLK-eGwWlydLjJu-3xwpzFcV4fGMSfwKwU/edit?usp=sharing
#   homework: |
#       - HW1 Due, HW2 Released
#       - [HW2 Solutions](https://nbviewer.jupyter.org/github/DS-100/fa18/blob/master/hw/hw2/hw2.ipynb)
#   resources: |
#     - [Textbook: Working With Text](https://www.textbook.ds100.org/ch/08/text_intro.html)
#     - [Screencast](https://www.youtube.com/watch?v=7jJlJU7bFe8)
#     - [code and data (includes notebooks and scripts as needed)](assets/lectures/lec07/code.zip)

# - date: 9/18/18
#   topic: Modeling and Estimation
#   description: How do we pick a number to represent a dataset? A key step in
#     data science is developing models that capture the essential signal in
#     data while providing insight into the phenomena that govern the data and
#     enable effective prediction. In this lecture we address the fundamental
#     question of choosing a number and more generally a model that reflects
#     the data. We will introduce the concept of loss functions and begin to
#     develop basic models. we will explore how calculus can be used to
#     analytically and minimize loss functions.
#   slides: assets/lectures/lec08/08-modeling-and-estimation.pptx
#   lab: |
#     - Lab4
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab04/lab04_solution.ipynb)
#   discussion: |
#     - [Disc4](https://github.com/DS-100/fa18/blob/master/disc/disc04/disc04.pdf)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc04/disc04_solution.pdf)
#     - [TA Slides](https://docs.google.com/presentation/u/1/d/1jKMDmWBLsS5KkywoYnaBmkuKPMOGNZYhB3ZKdjiTh5M/edit?usp=sharing)
#   resources: |
#     - [Textbook: Modeling and Estimation](https://www.textbook.ds100.org/ch/10/modeling_intro.html)
#     - [Estimation notebook (HTML Version)](assets/lectures/lec08/Estimation.html)
#     - [convex-functions notebook (HTML Version)](assets/lectures/lec08/convex-functions.html)
#     - [Screencast](https://www.youtube.com/watch?v=H55b-vAfBOc)
#     - [code and data (includes notebooks and scripts as needed)](assets/lectures/lec08/code.zip)

# - date: 9/20/18
#   topic: Modeling and Estimation II
#   description: In this lecture we will continue our development of models
#     within the framework of loss minimization. In particular, we will explore
#     how to numerically minimize loss functions. We will also introduce multidimensional
#     models and define the notion of the gradient of a function. To minimize functions,
#     we will introduce the widely used gradient descent algorithm.
#   slides: assets/lectures/lec09/09-modeling-and-estimation-II.pptx
#   resources: |
#     - [Textbook: Gradient Descent](https://www.textbook.ds100.org/ch/11/gradient_descent.html)
#     - [Demo Notebook](assets/lectures/lec09/09-Models-and-Estimation-II.ipynb)
#       - [HTML Version](assets/lectures/lec09/09-Models-and-Estimation-II.html)
#     - [Screencast](https://www.youtube.com/watch?v=ks5z4GQg6R0)


# - date: 9/25/18
#   topic: Generalization and Empirical Risk Minimization
#   description: So far, we have focused on how we can estimate a descriptive
#     statistic or more generally the parameters of a model that reflects our data.
#     What does this say about the population? How can we generalize beyond what we
#     observe? In this lecture we recast our loss minimization approach in the
#     context of empirical risk minimization. In the process we will review basic
#     probability concepts including expectation, bias, and variance.
#   lab: |
#     - Lab5
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab05/lab05_solution.ipynb)
#   discussion: |
#     - [Disc5](https://github.com/DS-100/fa18/blob/master/disc/disc05/disc05.pdf)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc05/disc05_solution.pdf)
#   homework: |
#     - HW2 Due, HW3 Released
#     - [HW3 Solutions](https://nbviewer.jupyter.org/github/DS-100/fa18/blob/master/hw/hw3/hw3.ipynb)
#   slides: assets/lectures/lec10/10-prob-generalization.pptx
#   resources: |
#     - [Textbook: Probability and Generalization](https://www.textbook.ds100.org/ch/12/prob_and_gen.html)
#     - [Screencast](https://www.youtube.com/watch?v=o3EQnGw-RIw)

# - date: 9/27/18
#   topic: Linear Regression and Feature Engineering
#   description: Linear regression is at the foundation of most machine learning
#     and statistical methods. We have already introduced linear models in an
#     informal way; in this lecture we formalize the setup of a linear model as
#     a parametric description of a dataset whose parameters can be estimated
#     computationally. We study the normal equations from the perspective of
#     optimization and discuss some of the computational issues around solving
#     the normal equations. We will then transition to the task of feature
#     engineering and describe a range of techniques for transforming data to
#     enable linear models to fit complex relationships.
#   slides: assets/lectures/lec11/11-linear_models.pptx
#   resources: |
#     - [Textbook: Linear Regression](https://www.textbook.ds100.org/ch/13/linear_models.html)
#     - [Textbook: Feature Engineering](https://www.textbook.ds100.org/ch/14/feature_engineering.html)
#     - [Notebook (HTML)](assets/lectures/lec11/11-Linear-Regression-and-Feature-Engineering.html)
#       - [Notebook (zip)](assets/lectures/lec11/lec11.zip)
#     - [Screencast](https://www.youtube.com/watch?v=4NRf1RJyJto)

# - date: 10/2/18
#   topic: Bias-Variance Tradeoff and Regularization
#   description: There is a fundamental tension in predictive modeling between
#     our ability to fit the data and to generalize to the world. In this lecture
#     we characterize this tension through the tradeoff between bias and variance.
#     We will derive the bias and variance decomposition of the least squares
#     objective. We then discuss how to manage this tradeoff by augmenting our
#     objective with a regularization penalty.
#   slides: assets/lectures/lec12/12-bias-variance-regularization.pptx
#   lab: |
#     - [Lab6](assets/labs/lab06.html)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab06/lab06_solution.ipynb)
#   discussion: |
#     - [Disc6](https://github.com/DS-100/fa18/blob/master/disc/disc06/disc06.pdf)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc06/disc06_solution.pdf)
#   resources: |
#     - [Textbook: Bias-Variance Tradeoff](https://www.textbook.ds100.org/ch/15/bias_intro.html)
#     - [Notebook (HTML)](assets/lectures/lec12/Bias_Variance_Regularization_Simplified.html)
#       - [Notebook (zip)](assets/lectures/lec12/code.zip)
#     - [Screencast](https://www.youtube.com/watch?v=uIzdjhm-7FI)

# - date: 10/4/18
#   topic: Cross-Validation and Regularization
#   description: In this lecture we will recap our discussion of linear
#     regression by reviewing how to use the scikit learn regression package. We
#     will then explore the challenges of overfitting and review how
#     regularization can be used to address overfitting. We will introduce
#     cross-validation as a mechanism to estimate the test error and to select
#     the regularization parameters.
#   slides: assets/lectures/lec13/13-cv_and_regularization.pptx
#   resources: |
#     - [Textbook: Regularization](https://www.textbook.ds100.org/ch/16/reg_intro.html)
#     - [Textbook: Cross-Validation](https://www.textbook.ds100.org/ch/15/bias_cv.html)
#     - [Bias-Variance and Regularization Notebook (HTML Version)](assets/lectures/lec13/code/Bias_Variance_and_Regularization.html)
#     - [Feature Engineering Part 1 Notebook (HTML Version)](assets/lectures/lec13/code/FeatureEngineeringPart1.html)
#     - [Feature_Engineering Part 2 Notebook (HTML Version)](assets/lectures/lec13/code/Feature_Engineering_Part_2.html)
#     - [Make Toy Data Notebook (HTML Version)](assets/lectures/lec13/code/data/Make Toy Data.html)
#     - [Screencast](https://www.youtube.com/watch?v=1dIKn177M1g)

# - date: 10/9/18
#   topic: Ethics
#   description: Data science is being used in growing number of settings to
#     make decisions that impact people's lives. In this lecture we will discuss
#     just a few of the many ethical and legal considerations in the application
#     of data science to real-world problems. Our guest speaker Joshua Kroll is a
#     computer scientist and researcher interested in the governance of automated
#     decision-making systems, especially those built with machine learning. He
#     is currently a Postdoctoral Research Scholar at UC Berkeley’s School of
#     Information, working with Deirdre Mulligan. Before that he received a
#     PhD in Computer Science in the Security Group at Princeton University.
#     His dissertation on Accountable Algorithms was advised by Edward W.
#     Felten and supported by the Center for Information Technology Policy
#     where he studied topics in security, privacy, and technology’s impact
#     on policy decisions. Joshua was the program chair of this year’s edition
#     of the successful workshop series “Fairness, Accountability, and
#     Transparency in Machine Learning (FAT/ML)”.
#   slides: assets/lectures/lec14/2018-10-09_ethics-in-data-science.pptx
#   lab: |
#     - Lab7
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab07/lab07_solution.ipynb)
#   discussion: |
#     - [Disc7](https://github.com/DS-100/fa18/blob/master/disc/disc07/disc07.pdf)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc07/disc07_sol.pdf)
#   homework: |
#     - HW3 Due, Proj1 Released
#     - [Proj1 Solutions](https://github.com/DS-100/fa18/blob/master/proj/proj1/proj1.ipynb)
#   resources: |
#     - [Screencast](https://www.youtube.com/watch?v=AxZDMit8RBY)

# - date: 10/11/18
#   topic: Midterm Review Part 1
#   slides: https://docs.google.com/presentation/d/1NGPIcohNqH1sccpgTg-wnJaxtsiq5W0N2uRj3n-izpM/edit?usp=sharing
#   description: This lecture will review key topics from the course that
#     will be covered on the midterm.
#   resources: |
#     - [Screencast](https://www.youtube.com/watch?v=pHqBMtmeP-8)

# - date: 10/16/18
#   topic: Midterm Review Part 2
#   slides: https://docs.google.com/presentation/d/1WfxgLNBkscoQEimVmZ__b3PxJxSpkXGflr02zL1eMyw/edit?usp=sharing
#   description: The midterm will take place on 10/17 from 8-10 PM.
#   lab: Midterm Review (Lab8)
#   discussion: Midterm OH
#   resources: |
#     - [Screencast](https://www.youtube.com/watch?v=rtVwx-UY3A4)

# - date: 10/18/18
#   topic: Classification and Logistic Regression I
#   description: We consider the case in which our response is categorical;
#     in particular, we focus on the simple case in which the response has two
#     categories. We begin by using least squares to fit the binary response to
#     categorical explanatory variables and find that the predictions are
#     proportions. Next, we consider a more complex model (the linear probability
#     model) that is linear in quantitative explanatory variables, and we uncover
#     the limitations of this model. We motivate an alternative model, the
#     logistic, by examining a local linear fit and matching its shape. We also
#     draw connections between the logistic and log odds. Lastly, we introduce
#     an alternative loss function (the Kullback-Leibler divergence) that is
#     more appropriate for working with probabilities. We derive a representation
#     of the K-L divergence for binary response variables.
#   slides: assets/lectures/lec17/17-classification.pptx
#   resources: |
#     - [Textbook: Classification](https://www.textbook.ds100.org/ch/17/classification_intro.html)
#     - [Extra Plots notebook (HTML Version)](assets/lectures/lec17/code/ExtraPlots.html)
#     - [Logistic Regression Part 1 notebook (HTML Version)](assets/lectures/lec17/code/LogisticRegressionPart1.html)
#     - [Logistic Regression Part 2 notebook (HTML Version)](assets/lectures/lec17/code/LogisticRegressionPart2.html)
#     - [Notebook (zip)](assets/lectures/lec17/code.zip)
#     - [Screencast](https://www.youtube.com/watch?v=CO6WBGTlWQk)

# - date: 10/23/18
#   topic: Classification and Logistic Regression II
#   description: Continued discussion of material in the previous lecture.
#   lab: 'Project 1 OH '
#   discussion: |
#     - [Disc8](https://github.com/DS-100/fa18/blob/master/disc/disc08/disc08.pdf)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc08/disc08-sol.pdf)
#   slides: assets/lectures/lec18/18-classification_part2.pptx
#   resources: |
#     - [Screencast](https://www.youtube.com/watch?v=MMqhh_Xs-24)


# - date: 10/25/18
#   topic: Probability theory, Monte Carlo, Bootstrapping
#   description: We saw previously that we can study parameter estimators
#     using theoretical and computational approaches. In this lecture we will
#     delve deeper into the bootstrap to study the behavior of the empirical
#     75th percentile as an estimator for its population counterpart. We will
#     derive the empirical quantile through the optimization of a loss function,
#     show that the population parameter minimizes the expected loss, bootstrap
#     the sampling distribution of the empirical 75th percentile, and use the
#     bootstrapped distribution to provide interval estimates for the population
#     parameter.
#   slides: assets/lectures/lec19/19-boostrap-mc.pptx
#   homework: |
#     - Proj1 Due, HW4 Released
#     - [HW4 Solutions](https://github.com/DS-100/fa18/blob/master/hw/hw4/hw4.ipynb)
#   resources: |
#     - [Central Limit Theorem notebook](assets/lectures/lec19/central-limit.ipynb)
#     - [PRNG notebook](assets/lectures/lec19/prngs.ipynb)
#     - [Restaurant Estimation notebook](assets/lectures/lec19/restaurant-estimation.ipynb)
#     - [Screencast](https://www.youtube.com/watch?v=GogImv9GrwE)

# - date: 10/30/18
#   topic: Hypothesis Testing I
#   description: A key step in inference is often answering a question about
#     the world. We will consider two such questions to varying degrees of
#     detail. 1) Is there enough evidence to bring someone to trial? 2) Do female
#     TAs get lower teaching evaluations than male TAs? We use hypothesis testing
#     to answer these questions. In particular, we examine a collection of
#     non-parametric hypothesis tests. These powerful procedures build on the
#     basic idea of random simulation to help quantify the rarity of a particular
#     phenomenon. In the process of using these procedures we will also touch on
#     the challenges of false discovery and multiple testing.
#   lab: |
#     - Lab9
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab09/lab09_solution.ipynb)
#   discussion: |
#     - [Disc9](https://github.com/DS-100/fa18/blob/master/disc/disc09/disc09.pdf)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc09/disc09_sol.pdf)
#   slides: https://docs.google.com/presentation/d/1r7apHpdxTqlBi8oSVe5k45MtcwA_BJ9AvVmaiNBQ15k/edit?usp=sharing
#   resources: |
#     - [Textbook: Statistical Inference](https://www.textbook.ds100.org/ch/18/hyp_intro.html)
#     - [Notebook (ipynb)](assets/lectures/lec20/lec20.ipynb)
#     - [Notebook (html)](assets/lectures/lec20/lec20.html)
#     - [Screencast](https://www.youtube.com/watch?v=sBBdooFWTeM)

# - date: 11/1/18
#   topic: Numerical issues, condition numbers, higher dimensions
#   description: This is a new lecture for this semester.
#   resources: |
#     - [Screencast](https://www.youtube.com/watch?v=0km4NFT605U)
#     - Notebooks (HTML)
#       - [KL Divergence](assets/lectures/lec21/KL_Divergence.html)
#       - [Numerical Chaos](assets/lectures/lec21/21-numerical-chaos.html)
#       - [Monte Carlo ND](assets/lectures/lec21/MonteCarlo-nd.html)
#       - [Condition Number](assets/lectures/lec21/condition-number.html)
#       - [Volumes in ND](assets/lectures/lec21/vols_nd.html)

# - date: 11/6/18
#   topic: SQL
#   description: Much of the important data in the world is stored in
#     relational database management systems. In this lecture we will introduce
#     the key concepts in relational databases including the relational data
#     model, basic schema design, and data independence. We will then begin to
#     dig into the SQL language for accessing and manipulating relational data.
#   slides: assets/lectures/lec22/22-sql.pptx
#   lab: |
#     - Lab10
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab10/lab10_solution.ipynb)
#   discussion: |
#     - [Disc10](https://github.com/DS-100/fa18/blob/master/disc/disc10/disc10.pdf)
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/disc/disc10/disc10_sol.pdf)
#   resources: |
#     - [Textbook: SQL](https://www.textbook.ds100.org/ch/09/sql_intro.html)
#     - [Notebook (ipynb)](assets/lectures/lec22/sql_introduction_part1.ipynb)
#     - [Notebook (html)](assets/lectures/lec22/sql_introduction_part1.html)
#     - [Screencast](https://www.youtube.com/watch?v=BSexiBTVj14)

# - date: 11/8/18
#   topic: Advanced SQL
#   description: In this lecture we review more advanced SQL queries including
#     joins and common table expressions, and we discuss how we can combine
#     computation in a database with Python.
#   slides: assets/lectures/lec23/23-advanced-sql.pptx
#   homework: |
#     - HW4 Due, HW5 Released
#     - [HW5 Solutions](https://github.com/DS-100/fa18/blob/master/hw/hw5/hw5.ipynb)
#   resources: |
#     - [Notebook (ipynb)](assets/lectures/lec23/sql_introduction_part2.ipynb)
#     - [Notebook (html)](assets/lectures/lec23/sql_introduction_part2.html)
#     - [Screencast](https://www.youtube.com/watch?v=7exNl0BOfn0)

# - date: 11/13/18
#   topic: Big Data
#   description: Data management at the level of big organizations can be
#     confusing and often relies on many different technologies. In this
#     lecture we will provide an overview of organizational data management
#     and introduce some of the key technologies used to store large amounts
#     of data. We will introduce various data representation techniques for
#     database design, and we will discuss the tradeoffs between different
#     methods of enterprise data management.
#   lab: |
#     - Lab11
#     - [Solutions](https://github.com/DS-100/fa18/blob/master/labs/lab11/lab11_solution.ipynb)
#   discussion: Lab11
#   slides: assets/lectures/lec24/24-big-data.pdf
#   resources: |
#     - [Slides in PPT Format](assets/lectures/lec24/24-big-data.pptx)
#     - [Spark Demo (HTML)](assets/lectures/lec24/Spark.html)
#     - [Spark Demo (ipynb)](assets/lectures/lec24/Spark.ipynb)
#     - [Screencast](https://www.youtube.com/watch?v=EuxDwLlKwMY)
#   homework: |
#     - Proj2A Released, Grad Project Released
#     - [Proj2A Solutions](https://github.com/DS-100/fa18/tree/master/proj/proj2A)

# - date: 11/15/18
#   topic: Distributed Computing
#   description: Distributed computing is the process in which multiple
#     computers work together to accomplish a computational task. In this
#     lecture we will discuss various distributed computing methods that we
#     can use to work with data at scale. In particular, we will introduce
#     programming with Spark, a parallel execution engine for big data
#     processing.
#   slides: https://d1b10bmlvqabco.cloudfront.net/attach/jkopvsyuy7g3u0/hl75y4dig6u38v/joqrs9ol3u7h/20181115__DS100_lecture_on_machine_learning_and_distributed_systems.pdf
#   resources: |
#     - [Screencast](https://www.youtube.com/watch?v=GkVfHX-NUdk)
#     - [Ray Documentation](http://ray.readthedocs.io/en/latest/index.html)
#     - [Notebook](https://d1b10bmlvqabco.cloudfront.net/attach/jkopvsyuy7g3u0/hl75y4dig6u38v/joqrqhfv1zcj/DS100RayMLlecture.ipynb)

# - date: 11/20/18
#   topic: A/B Testing
#   description: It is now commonplace for organizations with websites or mobile
#     apps to run randomized controlled experiments, or “A/B tests” as they’re
#     often called in industry. Such experiments provide a reliable way to
#     determine which product changes lead to the most successful user
#     interactions. In this lecture we will discuss why randomized experiments
#     are so important, talk about some of the key design choices that go into
#     A/B tests, and get a brief introduction to sequential monitoring of
#     experimental results.
#   lab: 'Project 2 OH '
#   discussion: Break
#   slides: http://www.ds100.org/sp18/assets/lectures/lec28/28-randomized-experiments-ab-testing.pdf
#   homework: |
#     - HW6 Released, Proj2B Released
#     - [HW6 Solutions](https://github.com/DS-100/fa18/blob/master/hw/hw6/hw6.ipynb)
#     - [Proj2B Solutions](https://github.com/DS-100/fa18/tree/master/proj/proj2B)
#   resources: |
#     - [Screencast](https://youtu.be/gtrz_uPJ-fE)
#     - [Demo Notebook (HTML)](http://www.ds100.org/sp18/assets/lectures/lec28/sequential-experiments-demo.html)

# - date: 11/22/18
#   topic: Thanksgiving Break
#   description: Enjoy your break!

# - date: 11/27/18
#   topic: Data Commons
#   description: There will be a guest lecturer on this day.
#   slides: https://docs.google.com/presentation/d/1_kbcc_lMLdjD85q84jrlJfTUuHRCXAvc5GYXFheXsZQ/edit?usp=sharing
#   lab: |
#     - Lab12
#     - [Solutions](https://colab.research.google.com/drive/1KyksSuyGkOJJSION5_hbkHyuzaBRgkJv)
#   discussion: Lab12
#   homework: HW5 Due
#   resources: |
#     - [Screencast](https://www.youtube.com/watch?v=IB_qzPUVPus)

# - date: 11/29/18
#   topic: Conclusion
#   description: This is the last lecture.
#   slides: https://docs.google.com/presentation/d/1hduN1NoV0CQWvuvFL0Grv6MGYnors4zZ68Xxe91U3Dw/edit?usp=sharing
#   homework: Proj2A Due
#   resources: |
#     - [Screencast](https://www.youtube.com/watch?v=5izTC0rlqzc)

# - date: 12/4/18
#   topic: RRR week
#   description: This review lecture goes over material in the second half
#     of the course.
#   slides: https://docs.google.com/presentation/d/1VTPegzi0qoM83-_2X_BL1r8jHnreC4f4VKBwNdAx0ZA/edit?usp=sharing
#   homework: Proj2B Due
#   resources: |
#     - [Screencast](https://www.youtube.com/playlist?list=PLNSdoiHk6ujg9IGlEdn51sTKuc7ibDL0V)

# - date: 12/6/18
#   topic: RRR week
#   description: This review lecture goes over problems in the Spring 2018 Final.
#   homework: HW6 Due, Grad Project Due
#   resources: |
#     - [Screencast](https://www.youtube.com/playlist?list=PLQCcNQgUcDfrBO7dpL-Pv6e0LYGeqsHKr)

# - date: 12/11/18

# - date: 12/13/18
#   topic: Final Exam (11:30am-2:30pm)
